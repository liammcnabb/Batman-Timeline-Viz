# This repo is entirely written by Claude as a public example of a workflow. Since I do not pay for any AI, progress is limited by the amount of tokens I get per month.

# Spider-Man Villain Timeline

A visualization of Spider-Man villain appearances across the Amazing Spider-Man Vol. 1 comic book series (first 20 issues).

## ğŸš¨ For AI Agents

**MUST READ FIRST:** [AGENT_WORKFLOW_RULES.md](AGENT_WORKFLOW_RULES.md)

- Verification requirements (always check compiled output)
- Scraping guidelines (almost never necessary)
- Common failure patterns to avoid

## Project Overview

This project visualizes the chronological appearances of villains in the Spider-Man comics using data scraped from the Marvel Fandom website. The visualization is built with D3.js and displays which antagonists appear in each issue, allowing exploration of villain frequency and appearance patterns.

## Features

### Core Features

- **Web Scraper**: Automatically extracts antagonist information from Marvel Fandom pages
- **Data Processing**: Normalizes and structures villain data from comic issues
- **Interactive Visualization**: D3.js-based timeline graph showing villain appearances
- **Context Engineering**: Follows the context engineering protocol for maintainability and clarity

### Grid Visualization Features âœ¨ NEW

- **Data Filtering**: Hide villains with fewer than X appearances (default: 3)
- **Flexible Sorting**: Sort Y-axis by first appearance or longest chronological span
- **Magnification Controls**: Zoom from 0.5x to 16x with smooth 300ms transitions
- **Fullscreen Mode**: Present data on large screens with ESC to exit
- **Dark Theme**: Professional dark mode with automatic OS detection and persistent preferences
  - Light theme: Light gray background (#f5f5f5) with dark text
  - Dark theme: Dark background (#1a1a1a) with light text
  - Theme toggle button (ğŸŒ™/â˜€ï¸) in top-right corner
  - System preference auto-detection on first visit
  - Preference saved to localStorage

### Data Processing Features

- **Group Classification**: Automatically identifies and separates villain groups from individuals
- **GroupRegistry**: Curated registry of 16+ known Spider-Man villain groups with alias resolution
- **Identity Tracking**: Tracks whether villains are identified by URL or by name (with `identitySource` field)
- **Group Member Tracking**: Issue-specific member rosters for groups (no cross-issue reconciliation)
- **Deterministic Processing**: Auditable group classification with fallback pattern matching

See [COMPLETE_FEATURE_SET.md](COMPLETE_FEATURE_SET.md) for comprehensive feature documentation.

## Tech Stack

- **Frontend**: D3.js, HTML5, CSS3
- **Backend/Scraping**: Node.js + TypeScript, Cheerio, Axios
- **Data Processing**: Zod (runtime validation), SeriesName utility (format-agnostic names), GroupRegistry (deterministic classification)
- **Testing**: Jest (337 tests across 14 suites)
- **Build Tool**: TypeScript, npm

## Project Structure

```
spider-man-villain-timeline/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ index.ts              # Main CLI entry point (6 commands)
â”‚   â”œâ”€â”€ pipeline.ts           # Complete pipeline runner
â”‚   â”œâ”€â”€ scraper/
â”‚   â”‚   â””â”€â”€ marvelScraper.ts  # Marvel Fandom web scraper
â”‚   â”œâ”€â”€ visualization/
â”‚   â”‚   â”œâ”€â”€ D3ConfigBuilder.ts # Unified D3 config builder (PRIMARY)
â”‚   â”‚   â””â”€â”€ d3Graph.ts        # D3.js visualization logic (legacy)
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ ScrapeRunner.ts      # Scraping orchestration
â”‚       â”œâ”€â”€ ProcessRunner.ts     # Processing orchestration
â”‚       â”œâ”€â”€ MergeRunner.ts       # Merging orchestration
â”‚       â”œâ”€â”€ Publisher.ts         # Publishing orchestration
â”‚       â”œâ”€â”€ seriesName.ts        # Format-agnostic series names (NEW)
â”‚       â”œâ”€â”€ groupRegistry.ts     # Group classification registry (NEW)
â”‚       â”œâ”€â”€ groupClassifier.ts   # Group classification logic (UPDATED)
â”‚       â”œâ”€â”€ schemas.ts           # Zod validation schemas
â”‚       â”œâ”€â”€ errors.ts            # Typed error classes
â”‚       â”œâ”€â”€ commandParser.ts     # CLI argument parser
â”‚       â””â”€â”€ dataProcessor.ts     # Data normalization (UPDATED)
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw.{Series}.json                 # Raw scraped data
â”‚   â”œâ”€â”€ villains.{Series}.json            # Processed per-series data
â”‚   â”œâ”€â”€ d3-config.{Series}.json           # D3 config per-series
â”‚   â”œâ”€â”€ villains.json                     # Combined merged data
â”‚   â””â”€â”€ d3-config.json                    # Combined D3 config
â”œâ”€â”€ public/
â”‚   â”œâ”€â”€ index.html            # Main HTML page
â”‚   â”œâ”€â”€ style.css             # Styling
â”‚   â”œâ”€â”€ script.js             # Client-side D3 rendering
â”‚   â””â”€â”€ data/                 # Published data files
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ ARCHITECTURE.md       # System architecture (UPDATED with GroupRegistry)
â”‚   â”œâ”€â”€ CODE_GUIDELINES.md    # Code guidelines (UPDATED with group classification)
â”‚   â”œâ”€â”€ SERIES_NAME_UTILITY.md  # SeriesName utility API
â”‚   â”œâ”€â”€ CHECKPOINT_2_COMPLETION.md  # CHECKPOINT 2 report
â”‚   â””â”€â”€ REFACTOR_CHECKLIST.md # Refactoring progress (CHECKPOINT 3 complete)
â”œâ”€â”€ package.json
â”œâ”€â”€ tsconfig.json
â””â”€â”€ README.md
```

## Quick Start

### Prerequisites

- Node.js 16+
- npm or yarn

### Installation

```bash
# Clone or navigate to project directory
cd spider-man-villain-timeline

# Install dependencies
npm install

# Build TypeScript
npm run build
```

### Running the Complete Pipeline

The easiest way to run everything is the **complete pipeline** command:

```bash
# Run all steps: scrape â†’ process â†’ merge â†’ publish
npm run pipeline -- --series "Amazing Spider-Man Vol 1" --issues 1-50

# Or use full series
npm run pipeline -- --series "Untold Tales of Spider-Man Vol 1"
```

### Individual Commands

You can also run each step separately:

#### 1. Scrape Raw Data

```bash
# Scrape all series
npm run scrape -- --all-series

# Scrape specific series
npm run scrape -- --series "Amazing Spider-Man Vol 1" --issues 1-100

# Scrape specific issue range
npm run scrape -- --issues 1-20

# Scrape specific issues
npm run scrape -- --issues 1,5,10,20

# Scrape multiple ranges and specific issues
npm run scrape -- --issues 1-20,50-60,100

# Fast dev (avoid long scrapes)
npm run scrape -- --issues 1-20
```

### Processing Data (Process Phase - No Scraping Needed!)

**âš¡ Test the merge logic without scraping:**

```bash
# Process existing JSON files instantly (< 1 second)
npx ts-node test-merge-logic.ts
```

This loads existing series JSON files and tests the data merge logic.

**See docs for more:** [PULL_AND_PROCESS.md](docs/PULL_AND_PROCESS.md)

### View Results

```bash
npm run serve
# Opens http://localhost:8000
```

This creates:

- `data/villains.json` - Combined data for all series
- `data/d3-config.json` - Visualization configuration

#### Scraping Options

- `--issues, -i <spec>`: Specify which issues to scrape
  - Single issue: `1`
  - Range: `1-20`
  - Multiple issues: `1,5,10,20`
  - Combined: `1-20,50-60,100`
- `--volume, -v <name>`: Specify which volume to scrape (default: "Amazing Spider-Man Vol 1")
  - Currently supports: Vol 1 (1-441), Vol 2 (1-58), Vol 3 (1-20), Vol 4 (1-32), Vol 5 (1-93)

### Viewing the Visualization

```bash
# Start a local HTTP server
npm run serve
```

Then open `http://localhost:8000` in your browser.

## Architecture: Pull â†’ Process â†’ Publish

The data pipeline is separated into three independent phases:

```
Pull Phase          Process Phase         Publish Phase
(Scraping)          (Merge & Transform)   (Visualize & Output)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Marvel Fandom  â†’  mergeDatasets()  â†’  D3.js visualization
JSON Files     â†’  (mergeDatasets.ts) â†’ HTML/Browser
```

### Phase Separation Benefits

**Pull (Scraping)**

- Fetches data from Marvel Fandom
- Creates series-specific JSON files
- Can be run independently
- Command: `npm run scrape -- --all-series`

**Process (Merge & Transform)**

- Pure function: `mergeDatasets(datasets)` in `src/utils/mergeDatasets.ts`
- No I/O dependencies
- Can be tested without scraping
- Command: `npx ts-node test-merge-logic.ts`

**Publish (Visualization)**

- Generates D3 configs and HTML
- Updates public data directory
- Can reuse existing data files

### Development Workflow

For **data processing changes** (fast iteration):

```bash
# 1. Edit src/utils/mergeDatasets.ts
# 2. Rebuild
npm run build
# 3. Test immediately (no scraping!)
npx ts-node test-merge-logic.ts
# Verification: < 1 second âš¡
```

For **complete pipeline**:

```bash
npm run build      # Build TypeScript
npm test           # Run 93 unit tests
npm run scrape -- --all-series  # Scrape all data
npm run serve      # View in browser
```

**See [docs/PULL_AND_PROCESS.md](docs/PULL_AND_PROCESS.md) for detailed workflow.**

## Development

### Project Setup with Context Engineering

This project uses the Context Engineering Protocol for:

- Clear component boundaries
- Documented tool definitions
- Feedback-driven optimization
- Proof steps for testing

See [ARCHITECTURE.md](docs/ARCHITECTURE.md) for details.

### Code Guidelines

Follow the standards in [GUIDELINES.md](docs/GUIDELINES.md):

- Max 110 character line length
- Max 3 levels of nesting
- Max 80 lines per function
- TypeScript strict mode enabled

### Testing Strategy

```bash
# Fast data processing tests (< 1 second)
npx ts-node test-merge-logic.ts

# Full unit test suite (93 tests)
npm test

# With coverage
npm test -- --coverage
```

### Workflow

1. **Pull (Scraping)**: `src/scraper/` handles Marvel Fandom extraction
2. **Process (Merging)**: `src/utils/mergeDatasets.ts` normalizes and deduplicates data
3. **Visualization**: `src/visualization/` generates D3.js logic
4. **Frontend**: `public/` contains the interactive interface

## Next Steps

### Short Term

- [x] Complete scraper for issues 1-20
- [x] Create basic D3 timeline visualization
- [x] Separate pull and process logic
- [ ] Add interactive filtering by villain
- [x] Create specific D3 gantt plot to explore as one chart

### Medium Term

- [ ] Extend scraper to all 800+ issues
- [ ] Add villain statistics (first appearance, frequency)
- [ ] Implement villain relationship visualization
- [ ] Extend Interaction with the marvel fandom website
- [ ] Consider Arc's/Saga's ([Part of the End of Spider-Man arc](https://marvel.fandom.com/wiki/End_of_Spider-Man))
- [ ] Create animated Group dynamics visualisation (showing how team members change)

### Long Term

- [ ] Support multiple Spider-Man series (2099, Ultimate, etc.)
- [ ] Add comics from other Marvel properties
- [ ] Historical analysis of villain popularity trends
- [ ] Attempt to make this compatable with a DC wiki (Batman?)

## Coverage Checklist

Maintenance note: Keep this checklist up to date after scrapes; tick items once series/annuals appear in `data/` and `public/data/`.

- Amazing Spider-Man (Primary canon)
  - [x] Vol. 1 (1963â€“1998) #1â€“441
  - [ ] Vol. 2 (1999â€“2003) #1â€“58
  - [ ] Vol. 1 resumed #500â€“545
  - [ ] Vol. 3 (2014â€“2015) #1â€“18
  - [ ] Vol. 4 (2015â€“2018) #1â€“32, #789â€“801
  - [ ] Vol. 5 (2018â€“2022) #1â€“93
  - [ ] Vol. 6 (2022â€“2024) #1â€“60
  - [ ] Vol. 7 (2024â€“present)

- Peter Parker, The Spectacular Spider-Man
  - [ ] Vol. 1 (1976â€“1998)
  - [ ] Vol. 2 (1999â€“2003)
  - [ ] Vol. 3 (2017â€“2018)

- Web of Spider-Man
  - [ ] Vol. 1 (1985â€“1995)

- Spider-Man (Adjectiveless)
  - [ ] Vol. 1 (1990â€“1998)
  - [ ] Vol. 2 (2004â€“2006)

- Sensational Spider-Man
  - [ ] Vol. 1 (1996â€“1998)

- Parallel Ongoings
  - [ ] Friendly Neighborhood Spider-Man Vol. 1 (2005â€“2007)
  - [ ] Friendly Neighborhood Spider-Man Vol. 2 (2019)
  - [ ] Spider-Man Unlimited Vol. 1 (1993â€“1998)
  - [x] Untold Tales of Spider-Man Vol. 1 (1995â€“1997)
  - [ ] Superior Spider-Man Vol. 1 (2013â€“2014)
  - [ ] Superior Spider-Man Vol. 2 (2018â€“2019)
  - [ ] The Lost Years

- Canon Minis & Events
  - [ ] Spider-Man: The Other
  - [ ] Back in Black
  - [ ] One More Day (2007)
  - [ ] Spider-Man: Blue

- Clone Saga
  - [ ] Clone Saga material (retained with revisions)

- Full Retcons
  - [ ] Sins Past (retconned 2021)

- Annuals
  - [x] Amazing Spider-Man Annual (#1â€“present)
  - [ ] Spectacular Spider-Man Annual
  - [ ] Web of Spider-Man Annual
  - [ ] Sensational Spider-Man Annual
  - [ ] Spider-Man (Adjectiveless) Annual

- Team-Up Books
  Note: Requires additional work to select only volumes/issues where Spider-Man is a Featured Character.
  Status: Blocked until Featured Character filtering exists.
  - [ ] Marvel Team-Up
  - [ ] Spider-Man Team-Up
  - [ ] Avenging Spider-Man
  - [ ] Spider-Man & Deadpool
- Extended Scope (616 Canon Spiders)
  Note: Explicitly build on separation and union â€” own pages, shared data, and unified form if requested.
  Status: Blocked until separation/union feature exists.
  - Miles Morales
    - [ ] Spider-Man (Miles Morales) Vol. 2 (2016â€“2018)
    - [ ] Miles Morales: Spider-Man Vol. 1 (2018â€“2022)
    - [ ] Miles Morales: Spider-Man Vol. 2 (2022â€“present)
    - [ ] Spider-Men (2012)
    - [ ] Spider-Men II (2017)

  - Ben Reilly (Clone Legacy)
    - [ ] Sensational Spider-Man (1996â€“1998)
    - [ ] Scarlet Spider Vol. 1 (1995â€“1996)
    - [ ] Scarlet Spider Vol. 2 (2012â€“2014)
    - [ ] Scarlet Spider Vol. 3 (2017)

  - Kaine Parker
    - [ ] Scarlet Spider (2012â€“2014)

  - Cindy Moon (Silk)
    - [ ] Silk Vol. 1 (2015)
    - [ ] Silk Vol. 2 (2015â€“2016)
    - [ ] Silk Vol. 3 (2021â€“2022)

  - Jessica Drew (Spider-Woman)
    - [ ] Spider-Woman Vol. 5 (2014â€“2017)
    - [ ] Spider-Woman Vol. 7 (2020â€“2021)

## Resources

- [Marvel Fandom - Amazing Spider-Man Vol 1](https://marvel.fandom.com/wiki/Amazing_Spider-Man_Vol_1_1)
- [D3.js Documentation](https://d3js.org)
- [Context Engineering Template](../context-engineering-template)
